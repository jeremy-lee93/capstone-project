{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:07:22.397149Z",
     "start_time": "2021-06-07T01:07:11.667159Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import twint\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:07:45.916671Z",
     "start_time": "2021-06-07T01:07:45.902684Z"
    }
   },
   "outputs": [],
   "source": [
    "nest_asyncio.apply() #run this cell to prevent runtime errors when using twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:07:49.621751Z",
     "start_time": "2021-06-07T01:07:49.612524Z"
    }
   },
   "outputs": [],
   "source": [
    "#function to scrape tweets and create a dataframe of tweets\n",
    "def create_tweets_dataframe(username, start_date, end_date):\n",
    "    \n",
    "    \"\"\"This function will scrape all tweets from a specified account and create a dataframe with relevant \n",
    "    information.  There are three inputs: username, start_date, end_date.\n",
    "    \n",
    "    Username: Should be a string and match the handle of the Twitter account without the '@' symbol.\n",
    "    \n",
    "    start_date: Should be a string following the format 'YYYY-MM-DD.'\n",
    "    \n",
    "    end_date: Should be a string following the format 'YYYY-MM-DD.' \"\"\"\n",
    "    \n",
    "    c = twint.Config() #instantiate Twint\n",
    "    c.Username = username #Twitter handle of account\n",
    "    c.Since = start_date #date to start scraping tweets\n",
    "    c.Until = end_date #last date to scrape tweets\n",
    "    c.Pandas = True #enabled so data can be stored in a dataframe\n",
    "    c.Hide_output = True #prevent notebook from displaying all scraped tweets in the output cell\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    dataframe = twint.storage.panda.Tweets_df\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:12:35.162292Z",
     "start_time": "2021-06-07T01:12:27.459882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "yahoo_df = create_tweets_dataframe('YahooSportsNBA', '2021-03-01', '2021-06-06')\n",
    "yahoo_df.to_csv('yahoo_march_june21.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:12:43.853249Z",
     "start_time": "2021-06-07T01:12:39.189593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "crossover_df = create_tweets_dataframe('TheCrossover', '2021-03-01', '2021-06-06')\n",
    "crossover_df.to_csv('crossover_march_june21.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:12:57.453354Z",
     "start_time": "2021-06-07T01:12:50.761987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "athletic_df = create_tweets_dataframe('TheAthleticNBA', '2021-03-01', '2021-06-06')\n",
    "athletic_df.to_csv('athletic_march_june21.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:13:00.962158Z",
     "start_time": "2021-06-07T01:12:59.182380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "slam_df = create_tweets_dataframe('Slamnewswire', '2021-03-01', '2021-06-06')\n",
    "slam_df.to_csv('slam_march_june_21.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:13:23.657453Z",
     "start_time": "2021-06-07T01:13:01.790653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "bball_news_df = create_tweets_dataframe('basketbllnews', '2021-03-01', '2021-06-06')\n",
    "bball_news_df.to_csv('bball_news_march_june_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:13:28.120875Z",
     "start_time": "2021-06-07T01:13:25.486236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "sb_nation_df = create_tweets_dataframe('SBNationNBA', '2021-03-01', '2021-06-06')\n",
    "sb_nation_df.to_csv('sb_nation_march_june_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T01:13:37.622775Z",
     "start_time": "2021-06-07T01:13:29.013067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "hoopshype_df = create_tweets_dataframe('hoopshype', '2021-03-01', '2021-06-06')\n",
    "hoopshype_df.to_csv('hoopshype_march_june_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
